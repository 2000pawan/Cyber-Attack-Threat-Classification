


# Import Important Library that used in data preprocessing and model Training.

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import warnings
warnings.filterwarnings('ignore')
from sklearn.preprocessing import StandardScaler,LabelEncoder
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.feature_selection import f_classif,SelectKBest
from sklearn.metrics import accuracy_score,precision_score,recall_score,classification_report,f1_score,confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC


# Import all csv file.
df=pd.read_csv('MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')         
df1=pd.read_csv('MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv')    
df2=pd.read_csv('MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv')          
df3=pd.read_csv('MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv')
df4=pd.read_csv('MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv')
df5=pd.read_csv('MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv')
df6=pd.read_csv('MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv')
df7=pd.read_csv('MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv')


print(df.shape)
print(df1.shape)
print(df2.shape)
print(df3.shape)
print(df4.shape)
print(df5.shape)
print(df6.shape)
print(df7.shape)


# Type of Attacks.

print(df[' Label'].unique())
print(df1[' Label'].unique())
print(df2[' Label'].unique())
print(df3[' Label'].unique())
print(df4[' Label'].unique())
print(df5[' Label'].unique())
print(df6[' Label'].unique())
print(df7[' Label'].unique())


# Function to fix encoding 
def fix_encoding(text):
    if isinstance(text, str):
        return text.encode('utf-8', 'ignore').decode('utf-8')  # Remove bad characters
    return text

# Apply fix to all DataFrames before merging
dfs = [df, df1, df2, df3, df4, df5, df6, df7]
for i in range(len(dfs)):
    dfs[i][' Label'] = dfs[i][' Label'].apply(fix_encoding)

# Merge all data frame into single dataframe 
merged_df = pd.concat(dfs, ignore_index=True)
merged_df=merged_df.sample(frac=1, random_state=42).reset_index(drop=True)

# Verify df5 labels exist in merged_df
print("Unique labels in merged_df after fix:", merged_df[" Label"].unique())
print(merged_df.shape)

# Export new dataframe.
df1=merged_df.iloc[:200001,:]
df2=merged_df.iloc[200001:,:]
df1.to_csv('cyberattack.csv',index=False)
df2.to_csv('cyberattack1.csv',index=False)








# Import new csv file.
df=pd.read_csv('cyberattack.csv')


# Knowing Initial Details about Data.

print(df.shape)
print('-----------------------------------------------------------------------------------------------------------------------------------')
print(df.info())
print('-----------------------------------------------------------------------------------------------------------------------------------')
print('Columns Names:- ',list(df.columns))
print('-----------------------------------------------------------------------------------------------------------------------------------')
print(df.describe())
print('-----------------------------------------------------------------------------------------------------------------------------------')
column_name=df.columns
print(column_name)


# Modifying or Removing Unwanted Data.

df.dropna(inplace=True)
df.drop_duplicates(inplace=True)
print(df.shape)
df = df.replace([np.inf, -np.inf], np.nan).dropna()
print(df.shape)


print(list(df[' Label'].unique()))





# Data Distribution using Displot

plt.figure(figsize=(10,6))
sns.countplot(x=df[" Label"], palette="coolwarm")
plt.xticks(rotation=90)
plt.title("Distribution of Attack Categories")
plt.xlabel("Attack Type")
plt.ylabel("Count")
plt.show()









X=df.iloc[:,:-1].values
y=df.iloc[:,-1].values
f_value,p_value=f_classif(X,y)
print(list(f_value))

# Most of the f_value score is greater than 100 so removed those feature which f_value is less than 100.
imp_feature_index=[]
unimp_feature_index=[]
count_imp_feature=0
count_unimp_feature=0
for i,j in enumerate(f_value):
    if j>100:
        count_imp_feature+=1
        imp_feature_index.append(i)
    else:
        count_unimp_feature+=1
        unimp_feature_index.append(i)
        
print('Total Important Feature:- ',count_imp_feature)
print('Total UnImportant Feature:- ',count_unimp_feature)


imp_feature_name=[column_name[i] for i in imp_feature_index]
unimp_feature_name=[column_name[i] for i in unimp_feature_index]


print('Important Feature Names:- ',list(imp_feature_name))
print('===============================================================================================================================================================================================')
print('UnImportant Feature Names:- ',list(unimp_feature_name))








# Retrive data feature and target
X_new=df.iloc[:,:-1].values
y_new=df.iloc[:,-1].values

# Select K Best Feature
k_best=SelectKBest(f_classif,k=52)
X_best=k_best.fit_transform(X_new,y_new)

# Split Dataset into Two Part.
X_train,X_test,y_train,y_test=train_test_split(X_best,y_new,random_state=1,test_size=0.30)

# Scale the Train and Test Data
sc=StandardScaler()
X_train_new=sc.fit_transform(X_train)
X_test_new=sc.fit_transform(X_test)





model=RandomForestClassifier(n_estimators=100,random_state=1,bootstrap=True)
model.fit(X_train_new,y_train)
pred_train=model.predict(X_train_new)
pred_test=model.predict(X_test_new)
print('Accuracy Score of Training Data:- ',accuracy_score(y_train,pred_train))
print('Accuracy Score of Testing Data:- ',accuracy_score(y_test,pred_test))


rm=accuracy_score(y_test,pred_test)
cm_train=confusion_matrix(y_train,pred_train)
cm_test=confusion_matrix(y_test,pred_test)
rm


print("Classification Report of Training Data:- \n ",classification_report(y_train,pred_train))
print('-----------------------------------------------------------------------------------------------------------------------------------------------')
print('-----------------------------------------------------------------------------------------------------------------------------------------------')
print('-----------------------------------------------------------------------------------------------------------------------------------------------')
print("Classification Report of Testing Data:- \n ",classification_report(y_test,pred_test))





# Graph of training Data
label=df[' Label'].unique()
enc=LabelEncoder()
enc.fit_transform(label)
plt.figure(figsize=(8,6))
sns.heatmap(cm_train, annot=True, fmt="d", cmap="Blues", xticklabels=enc.classes_, yticklabels=enc.classes_)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()


# Graph of testing Data
label=df[' Label'].unique()
enc=LabelEncoder()
enc.fit_transform(label)
plt.figure(figsize=(8,6))
sns.heatmap(cm_test, annot=True, fmt="d", cmap="Blues", xticklabels=enc.classes_, yticklabels=enc.classes_)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()








model1=SVC()
model1.fit(X_train_new,y_train)
pred_train=model1.predict(X_train_new)
pred_test=model1.predict(X_test_new)
print('Accuracy Score of Training Data:- ',accuracy_score(y_train,pred_train))
print('Accuracy Score of Testing Data:- ',accuracy_score(y_test,pred_test))


svm=accuracy_score(y_test,pred_test)
cm1_train=confusion_matrix(y_train,pred_train)
cm1_test=confusion_matrix(y_test,pred_test)


print("Classification Report of Training Data:- \n",classification_report(y_train,pred_train))
print('-----------------------------------------------------------------------------------------------------------------------------------------------')
print('-----------------------------------------------------------------------------------------------------------------------------------------------')
print('-----------------------------------------------------------------------------------------------------------------------------------------------')
print("Classification Report of Testing Data:- \n",classification_report(y_test,pred_test))





plt.figure(figsize=(10,5))
sns.barplot(x=["Random Forest",'SVM'], y=[rm,svm], palette='Blues_r')
plt.title("Accuracy Score of two model")
plt.xlabel("Model")
plt.ylabel("accuracy_score")
plt.show()





# Graph of training Data
label=df[' Label'].unique()
enc=LabelEncoder()
enc.fit_transform(label)
plt.figure(figsize=(8,6))
sns.heatmap(cm1_train, annot=True, fmt="d", cmap="Blues", xticklabels=enc.classes_, yticklabels=enc.classes_)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()


# Graph of testing Data
label=df[' Label'].unique()
enc=LabelEncoder()
enc.fit_transform(label)
plt.figure(figsize=(8,6))
sns.heatmap(cm1_train, annot=True, fmt="d", cmap="Blues", xticklabels=enc.classes_, yticklabels=enc.classes_)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()








plt.figure(figsize=(12,20))
sns.barplot(x=f_value, y=df.columns[:-1], palette='Blues_r')
plt.title("Top 52 Important Features")
plt.xlabel("Feature Importance Score")
plt.ylabel("Feature")
plt.show()


plt.figure(figsize=(12, 20))
plt.barh(df.columns[:-1], f_value, color='skyblue')
plt.xlabel("Score")
plt.ylabel("Feature Name")
plt.title("Feature Importance")
plt.gca().invert_yaxis()  # To show the highest score at the top
plt.show()


plt.figure(figsize=(12,20))
plt.scatter(f_value, df.columns[:-1], color='red')
plt.xlabel("Scores")
plt.ylabel("Features")
plt.title("Feature Score Distribution")
plt.xticks(rotation=45)
plt.show()








df2=pd.read_csv('cyberattack1.csv')


df3=df2.iloc[:5000:]
df3=df3.replace([np.inf, -np.inf], np.nan).dropna()
print(df3.shape)
x=df3.iloc[:,:-1].values
Y=df3.iloc[:,-1].values
x_best=k_best.transform(x)
x_new=sc.transform(x_best)


# Prediction using Random Forest
pred=model.predict(x_new)
print('Accuracy Score using Random Forest:- ',accuracy_score(Y,pred))


# Prediction using SVM
pred1=model1.predict(x_new)
print('Accuracy Score using SVM:- ',accuracy_score(Y,pred1))


plt.figure(figsize=(10,5))
sns.barplot(x=["Random Forest",'SVM'], y=[accuracy_score(Y,pred),accuracy_score(Y,pred1)], palette='Blues_r')
plt.title("Accuracy Score of two model")
plt.xlabel("Model")
plt.ylabel("accuracy_score")
plt.show()






